# K-means Clustering: why?
problems with Hierarchical clustering:
- runtime
- k-means is fast in large dataset
# K-means Clustering: how?
1. Generate cluster centers
    1. `k-means(obs,kk_or_guess,iter,thresh,check_finite)`
    2. return tow values: `cluster centers` and `distortion`
2.  Generate cluster labels
    1. `vq(obs,code_book,check_finite)`
    1. code_book is clster center returned by the kmeans function
    3. return two variables `cluster_labels` and a `list of distortions`
# k-means clustering: first exercise:
We apply the two step dance:
```python
# Import the kmeans and vq functions
from scipy.cluster.vq import kmeans, vq

# Generate cluster centers
cluster_centers, distortion = kmeans(comic_con[['x_scaled','y_scaled']] ,2)

# Assign cluster labels
comic_con['cluster_labels'], distortion_list = vq(comic_con[['x_scaled','y_scaled']], cluster_centers)
```
Now, we draw and see:
``` py
# Plot clusters
sns.scatterplot(x='x_scaled', y='y_scaled', 
                hue='cluster_labels', data = comic_con)
plt.show()
```
![kmeans clustering](img/Figure%201.svg)

# Faster :)
Kmeans clustering is exponentially faster than hierarchical clustering.

# How many clusters?
we draw an elbow plot
## Drawing an elbow plot
The elbow plot generated by the below code is:
![elbow plot of our kmeans](img/Figure%202.svg)
```python 
distortions = []
num_clusters = range(1, 7)

# Create a list of distortions from the kmeans function
for i in num_clusters:
    cluster_centers, distortion = kmeans(comic_con[['x_scaled','y_scaled']],i)
    distortions.append(distortion)

# Create a DataFrame with two lists - num_clusters, distortions
elbow_plot = pd.DataFrame({'num_clusters': num_clusters, 'distortions': distortions})

# Creat a line plot of num_clusters and distortions
sns.lineplot(x='num_clusters', y='distortions', data = elbow_plot)
plt.xticks(num_clusters)
plt.show()
```
## How many clusters?
From the elbow plot, we see a sharp change in the "inclinaison" of the line at num_clusters of `2`.

## Uniform Distribution
let's draw an elbow plot for a uniform distribution

```python
distortions = []
num_clusters = range(2, 7)

# Create a list of distortions from the kmeans function
for i in num_clusters:
    cluster_centers, distortion = kmeans(uniform_data[['x_scaled', 'y_scaled']], i)
    distortions.append(distortion)

# Create a DataFrame with two lists - number of clusters and distortions
elbow_plot = pd.DataFrame({'num_clusters': num_clusters, 'distortions': distortions})

# Creat a line plot of num_clusters and distortions
sns.lineplot(x='num_clusters', y='distortions', data=elbow_plot)
plt.xticks(num_clusters)
plt.show()
```

    Elbow plot: 
![Elbow plot of a uniform distribution](img/Figure%203.svg)

the elbow is not well defined here. So we can't really choose.

# Limitation of K-Means clustering
- Find the right number of clusters _k_
- Impact of seeds
- Biased towards equal sized clusters

## Impact of Seeds
Let's see if seeds impact the comic con dataset

    code:
```py
# Import random class
from numpy import random

# Initialize seed
random.seed(0)

# Run kmeans clustering
cluster_centers, distortion = kmeans(comic_con[['x_scaled', 'y_scaled']], 2)
comic_con['cluster_labels'], distortion_list = vq(comic_con[['x_scaled', 'y_scaled']], cluster_centers)

# Plot the scatterplot
sns.scatterplot(x='x_scaled', y='y_scaled', 
                hue='cluster_labels', data = comic_con)
plt.show()
```

    plot:
![kmeans clustering of seed](img/Figure%204.svg)

These cluisters do not change as the dataset has clearly defined clusers.

We tried `[1,2,1000]`

## Uniform Data: mouse like data
Let's do kmeans clustering on a dataset having a mouuse like sjhape

```py

# Import the kmeans and vq functions
from scipy.cluster.vq import kmeans, vq

# Generate cluster centers
cluster_centers, distortion = kmeans(mouse[['x_scaled','y_scaled']],3)

# Assign cluster labels
mouse['cluster_labels'], distortion_list = vq(mouse[['x_scaled','y_scaled']],cluster_centers)

# Plot clusters
sns.scatterplot(x='x_scaled', y='y_scaled', 
                hue='cluster_labels', data = mouse)
plt.show()
```
    Plot:
![mouse likel kmeans](img/Figure%205.svg)

    kmeans is unable to capture the three visible clusters clearly. 

    The two clusters towards the top have taken in some points along the boundary. 

    This happens due to the underlying assumption in kmeans algorithm to minimize distortions which leads to clusters that are similar in terms of area.
# FIFA time
let's star by first preparing out stuff.
## Imports
we import hte libraries and the CSV file as a Dataframe
```py
from scipy.cluster.vq import kmeans,vq ,whiten
import matplotlib.pyplot as plt
import seaborn as sns
import pandas as pd
from numpy import random



fifa= pd.read_csv('data/fifa_18_sample_data.csv')
```
## Normalize
We normalize the data in question: `def` and `phy`
```py

fifa['scaled_def']=whiten(fifa['def'])
fifa['scaled_phy']=whiten( fifa['phy'])
```

perfect.
## Set a random seed
```py
random.seed([1000,2000])
```


## Fit the data into a k-means algorithm
```py
cluster_centers,_ = kmeans(fifa[['scaled_def', 'scaled_phy']], 3)
```
## Assign cluster labels
```py
fifa['cluster_labels'], _ = vq(fifa[['scaled_def', 'scaled_phy']], cluster_centers)
```

## Display cluster centers 
```py
print(fifa[['scaled_def', 'scaled_phy', 'cluster_labels']].groupby('cluster_labels').mean())
```
# Create a scatter plot through seaborn
![Scatter plot of kmeans clusternf fifa phys/def](img/Figure%206.png)
```py
sns.scatterplot(x="scaled_def", y='scaled_phy', hue='cluster_labels', data=fifa)
plt.show()
```
Enjoy :)